{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests \n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
    "# r = requests.get(url +\".html\")#, headers=headers)\n",
    "# # c = r.content\n",
    "# soup = BeautifulSoup(r, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def web_scrapping(urls):\n",
    "    #----------------ChromeDriver Function\n",
    "    def get_browser():\n",
    "\n",
    "        #----------------ChromeDriver for Selenium\n",
    "\n",
    "        path_to_chromedriver = ('./chromedriver')\n",
    "        browser = webdriver.Chrome(executable_path=path_to_chromedriver)\n",
    "        return browser\n",
    "    \n",
    "    #----------------HTML File Saving Function\n",
    "    def file_saving(url):\n",
    "        file_name = 'index.html'\n",
    "        browser = get_browser() #------------1st Function Called Here\n",
    "\n",
    "        #----------------Join URl to Chromedriver\n",
    "        url = url\n",
    "        browser.get(url)\n",
    "\n",
    "        #----------------Save to local\n",
    "        file_object = codecs.open(file_name, \"w\", \"utf-8\")\n",
    "        html = browser.page_source\n",
    "        file_object.write(html)\n",
    "        browser.close()\n",
    "        file_object.close()\n",
    "        return file_name\n",
    "    \n",
    "    #----------------Total Scrapping Function\n",
    "    def scrapping(file_name):\n",
    "\n",
    "        lis= []\n",
    "\n",
    "        with open(file_name, encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "            soup = BeautifulSoup(data, 'html.parser')\n",
    "            page1 = soup.find(\"section\", {\"id\":\"mc_content\", \"class\":\"clearfix\"})\n",
    "            f.close()\n",
    "\n",
    "        page = page1.find(\"section\",{\"class\":\"technical_anl\", \"id\":\"pc_technical\"})\n",
    "        page = page.find(\"div\", {\"class\":\"main_wrapper_res\"})\n",
    "        page = page.find(\"div\", {\"class\":\"tab-content\"})\n",
    "        page = page.find(\"div\", {\"class\":\"tab-pane fade in active\", \"id\":\"techan_daily\"})\n",
    "        page = page.find(\"div\", {\"class\":\"clearfix mt20\"})\n",
    "        page = page.find(\"div\", {\"class\":\"techrating tecinD\"})\n",
    "        \n",
    "        #----------------Name of the Company\n",
    "        #name = page1.find(\"section\", {\"class\":\"price_overview_wrap\", 'id':\"sec_quotes\"})\n",
    "        #name = name.find('div',{'class':'main_wrapper_res corporate-wrapper'})\n",
    "        #name = name.find('div', {\"class\":\"moneyprice_bx\"})\n",
    "        #name = name.find(\"h1\", {\"class\":\"pcstname\"}).text\n",
    "        #print(name)\n",
    "\n",
    "        #----------------Heading\n",
    "        head = page.findAll(\"div\", {\"class\":\"heade14txt\"})[0].text\n",
    "        heading = head.split()[0:2]\n",
    "        heading = heading[0]+\" \"+heading[1]\n",
    "        heading = heading.title()\n",
    "\n",
    "        #----------------Table\n",
    "        tabl = page.find(\"div\", {\"class\":\"mt15 CTR pb20\"})\n",
    "        tabl = tabl.find(\"div\", {\"class\":\"mt15\"})\n",
    "        tabl = tabl.find(\"table\", {\"class\":\"mctable1\"}).findAll(\"tr\")\n",
    "\n",
    "        row = {}\n",
    "        for i in range(0, len(tabl)):\n",
    "            row.update({tabl[i].findAll(\"td\")[0].text:tabl[i].findAll(\"td\")[1].text})\n",
    "\n",
    "        #----------------DataFrame\n",
    "        data = pd.DataFrame(row.items(), columns=(heading,\"Values\"))\n",
    "        data = data.set_index(data.columns[0])\n",
    "        #print(data,\"\\n\\n\")\n",
    "        \n",
    "#         #----------------Inserting into DataBase\n",
    "#         insert_to_outputDB(name, heading, data['Values'][0], data['Values'][1], data['Values'][2])\n",
    "#         show_data(\"output_database\")\n",
    "        \n",
    "\n",
    "        #----------------Save to CSV\n",
    "        #data.to_csv('index.csv')\n",
    "        return data, heading\n",
    "        \n",
    "    #----------------Function Calling\n",
    "    url = urls\n",
    "    html_name = file_saving(url)\n",
    "    csvdata, heading = scrapping(html_name)\n",
    "    \n",
    "    #----------------HTML File Delete\n",
    "    os.remove(html_name)\n",
    "    \n",
    "    #----------------CSV File Returning\n",
    "    return csvdata, heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "\n",
    "def insert_to_inputDB(CName, Lin, Stats):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    sql = \"INSERT INTO input_database (CompanyName, Link, Status) VALUES (%s, %s, %s)\"\n",
    "    val = (CName, Lin, Stats)\n",
    "    \n",
    "    mycursor.execute(sql, val)\n",
    "    mydb.commit()\n",
    "    mydb.close()\n",
    "\n",
    "def insert_to_outputDB(Input_Company_Id, Rate, Averages, Indicators, Crossovers, Date):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    sql = \"INSERT INTO output_database (CompanyId, Ratings, MovingAverages, TechnicalIndicators, MovingAveragesCrossovers, Date) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    val = (Input_Company_Id, Rate, Averages, Indicators, Crossovers, Date)\n",
    "    \n",
    "    mycursor.execute(sql, val)\n",
    "    mydb.commit()\n",
    "    mydb.close()\n",
    "\n",
    "def show_data(table_name):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    mycursor.execute(\"SELECT * FROM {}\".format(table_name))\n",
    "    for i in mycursor:\n",
    "        print(i)\n",
    "    mydb.close()\n",
    "    \n",
    "def delete_row_Output_DB(table_name, Id):\n",
    "    if table_name == \"output_database\":\n",
    "        mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "        mycursor = mydb.cursor()    \n",
    "        mycursor.execute(\"DELETE FROM {} WHERE Id={}\".format(table_name, Id))\n",
    "        mydb.commit()\n",
    "        mydb.close()\n",
    "        \n",
    "    elif table_name == \"input_database\":\n",
    "        mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "        mycursor = mydb.cursor()    \n",
    "        mycursor.execute(\"DELETE FROM {} WHERE CompanyId={}\".format(table_name, Id))\n",
    "        mydb.commit()\n",
    "        mydb.close()\n",
    "        \n",
    "    else:\n",
    "        print(\"Give Correct Table Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector as mysql\n",
    "# import datetime\n",
    "\n",
    "# def scrap_and_DB(input_company_Id):\n",
    "#     mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "#     mycursor = mydb.cursor()\n",
    "#     mycursor.execute(\"SELECT * FROM input_database WHERE CompanyId={}\".format(input_company_Id))\n",
    "#     rows = mycursor.fetchall()\n",
    "#     mydb.close()\n",
    "\n",
    "#     if rows[0][3] == 1:\n",
    "#         time1 = datetime.datetime.now()\n",
    "\n",
    "#         csv_data, rating = web_scrapping(rows[0][2])\n",
    "#         insert_to_outputDB(rows[0][0], rating, csv_data['Values'][0], csv_data['Values'][1], csv_data['Values'][2], time1)\n",
    "#         print(\"Scrap & DB Done Take a Look\\n\")\n",
    "#         show_data(\"output_database\")\n",
    "\n",
    "#         time2 = datetime.datetime.now()\n",
    "#         print(\"\\n\\nTotal Time Taken To Scrap it -------------------------> \", time2-time1,\"\\n\")\n",
    "#     else:\n",
    "#         print(\"Status of {} is 0. Please check\".format(rows[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import datetime\n",
    "\n",
    "def scrap_and_DB():\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    mycursor.execute(\"SELECT * FROM input_database\")\n",
    "    rows = mycursor.fetchall()\n",
    "    mydb.close()\n",
    "\n",
    "#     if rows[0][3] == 1:\n",
    "#         time1 = datetime.datetime.now()\n",
    "\n",
    "#         csv_data, rating = web_scrapping(rows[0][2])\n",
    "#         insert_to_outputDB(rows[0][0], rating, csv_data['Values'][0], csv_data['Values'][1], csv_data['Values'][2], time1)\n",
    "#         print(\"Scrap & DB Done Take a Look\\n\")\n",
    "#         show_data(\"output_database\")\n",
    "\n",
    "#         time2 = datetime.datetime.now()\n",
    "#         print(\"\\n\\nTotal Time Taken To Scrap it -------------------------> \", time2-time1,\"\\n\")\n",
    "#     else:\n",
    "#         print(\"Status of {} is 0. Please check\".format(rows[0][1]))\n",
    "        \n",
    "    for i in range(0, len(rows)):\n",
    "        if rows[i][3] == 1:\n",
    "            time1 = datetime.datetime.now()\n",
    "\n",
    "            csv_data, rating = web_scrapping(rows[i][2])\n",
    "            insert_to_outputDB(rows[i][0], rating, csv_data['Values'][0], csv_data['Values'][1], csv_data['Values'][2], time1)\n",
    "            print(\"Scrap & DB Done Take a Look\\n\")\n",
    "\n",
    "            time2 = datetime.datetime.now()\n",
    "            print(\"\\n\\nTotal Time Taken To Scrap {} is -------------------------> \", time2-time1,\"\\n\".format(rows[i][1]))\n",
    "        else:\n",
    "            print(\"Status of {} having Company_Id = {} is 0. Please check\".format(rows[i][1], rows[i][0]))\n",
    "    \n",
    "    show_data(\"output_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'index.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-568a250399bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscrap_and_DB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-2e8c784793bd>\u001b[0m in \u001b[0;36mscrap_and_DB\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mtime1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mcsv_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweb_scrapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0minsert_to_outputDB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scrap & DB Done Take a Look\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1d6307a4ecba>\u001b[0m in \u001b[0;36mweb_scrapping\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m#----------------HTML File Delete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m#----------------CSV File Returning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'index.html'"
     ]
    }
   ],
   "source": [
    "scrap_and_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_row_Output_DB('output_database', i)\n",
    "show_data(\"output_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'ICICI Bank Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/icicibank/ICI02', 1)\n",
      "(2, 'Reliance Industries Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/refineries/relianceindustries/RI', 1)\n",
      "(3, 'State Bank of India', 'https://www.moneycontrol.com/india/stockpricequote/banks-public-sector/statebankindia/SBI', 1)\n",
      "(4, 'Vodafone Idea Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/telecommunications-service/vodafoneidealimited/IC8', 0)\n",
      "(5, 'Infosys Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT', 1)\n"
     ]
    }
   ],
   "source": [
    "insert_to_inputDB(\"Infosys Ltd.\", 'https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT', 1)\n",
    "show_data(\"input_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"UPDATE customers SET address = 'Canyon 123' WHERE address = 'Valley 345'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'ICICI Bank Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/icicibank/ICI02', 1)\n"
     ]
    }
   ],
   "source": [
    "mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"UPDATE input_database SET Status = 1 WHERE CompanyId = 1\")\n",
    "mydb.commit()\n",
    "mydb.close()\n",
    "show_data(\"input_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-29'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "time1 = datetime.datetime.now().date()\n",
    "time1 = time1.strftime('%Y-%m-%d')\n",
    "time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 'Technical Rating', 'Awesome', 'Bearish', 'Neutral', datetime.date(2020, 8, 29))\n",
      "(2, 2, 'Technical Rating', 'Awesome', 'Bearish', 'Neutral', datetime.date(2020, 8, 29))\n"
     ]
    }
   ],
   "source": [
    "insert_to_outputDB(2, \"Technical Rating\", 'Awesome', 'Bearish', 'Neutral', time1)\n",
    "show_data(\"output_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "file_name = \"YB.html\"\n",
    "with open(file_name, encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    page = soup.find(\"section\", {\"id\":\"mc_content\", \"class\":\"clearfix\"})\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes Bank Ltd.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = page.find(\"section\", {\"class\":\"price_overview_wrap\", 'id':\"sec_quotes\"})\n",
    "name = name.find('div',{'class':'main_wrapper_res corporate-wrapper'})\n",
    "name = name.find('div', {\"class\":\"moneyprice_bx\"})\n",
    "name = name.find(\"h1\", {\"class\":\"pcstname\"}).text\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = page.findAll(\"div\", {\"class\":\"heade14txt\"})[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technical Rating'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading = head.split()[0:2]\n",
    "heading = heading[0]+\" \"+heading[1]\n",
    "heading = heading.title()\n",
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabl = page.find(\"div\", {\"class\":\"mt15 CTR pb20\"})\n",
    "tabl = tabl.find(\"div\", {\"class\":\"mt15\"})\n",
    "tabl = tabl.find(\"table\", {\"class\":\"mctable1\"}).findAll(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {}\n",
    "for i in range(0, len(tabl)):\n",
    "    row.update({tabl[i].findAll(\"td\")[0].text:tabl[i].findAll(\"td\")[1].text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = []\n",
    "# row_1 = []\n",
    "# row_2 = []\n",
    "# for i in range(0, len(tabl)):\n",
    "#     row_1.append(tabl[i].findAll(\"td\")[0].text)\n",
    "#     row_2.append(tabl[i].findAll(\"td\")[1].text)\n",
    "# row.append(row_1)\n",
    "# row.append(row_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Moving Averages': 'Bullish',\n",
       " ' Technical Indicators': 'Bullish',\n",
       " 'Moving Averages Crossovers': 'Bullish'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(row.items(), columns=(heading,None))\n",
    "data = data.set_index(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('infosys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "\n",
    "# def get_html(url):\n",
    "#     f=open('htmlcode.txt','w')\n",
    "#     page=urllib.request.urlopen(url)\n",
    "#     pagetext=page.read() ## Save the html and later save in the file\n",
    "#     f.write(pagetext)\n",
    "#     f.close()\n",
    "    \n",
    "# get_html(\"https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT.html\")\n",
    "\n",
    "# import urllib.request\n",
    "\n",
    "# urllib.request.urlretrieve(\"https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT.html\", \"test.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
