{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests \n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
    "# r = requests.get(url +\".html\")#, headers=headers)\n",
    "# # c = r.content\n",
    "# soup = BeautifulSoup(r, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def web_scrapping(urls):\n",
    "    #----------------ChromeDriver Function\n",
    "    def get_browser():\n",
    "\n",
    "        #----------------ChromeDriver for Selenium\n",
    "\n",
    "        path_to_chromedriver = ('./chromedriver')\n",
    "        browser = webdriver.Chrome(executable_path=path_to_chromedriver)\n",
    "        return browser\n",
    "    \n",
    "    #----------------HTML File Saving Function\n",
    "    def file_saving(url):\n",
    "        file_name = 'index.html'\n",
    "        browser = get_browser() #------------1st Function Called Here\n",
    "\n",
    "        #----------------Join URl to Chromedriver\n",
    "        url = url\n",
    "        browser.get(url)\n",
    "\n",
    "        #----------------Save to local\n",
    "        file_object = codecs.open(file_name, \"w\", \"utf-8\")\n",
    "        html = browser.page_source\n",
    "        file_object.write(html)\n",
    "        browser.close()\n",
    "        file_object.close()\n",
    "        return file_name\n",
    "    \n",
    "    #----------------Total Scrapping Function\n",
    "    def scrapping(file_name):\n",
    "\n",
    "        lis= []\n",
    "\n",
    "        with open(file_name, encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "            soup = BeautifulSoup(data, 'html.parser')\n",
    "            page1 = soup.find(\"section\", {\"id\":\"mc_content\", \"class\":\"clearfix\"})\n",
    "            f.close()\n",
    "\n",
    "        page = page1.find(\"section\",{\"class\":\"technical_anl\", \"id\":\"pc_technical\"})\n",
    "        page = page.find(\"div\", {\"class\":\"main_wrapper_res\"})\n",
    "        page = page.find(\"div\", {\"class\":\"tab-content\"})\n",
    "        page = page.find(\"div\", {\"class\":\"tab-pane fade in active\", \"id\":\"techan_daily\"})\n",
    "        page = page.find(\"div\", {\"class\":\"clearfix mt20\"})\n",
    "        page = page.find(\"div\", {\"class\":\"techrating tecinD\"})\n",
    "        \n",
    "        #----------------Name of the Company\n",
    "        #name = page1.find(\"section\", {\"class\":\"price_overview_wrap\", 'id':\"sec_quotes\"})\n",
    "        #name = name.find('div',{'class':'main_wrapper_res corporate-wrapper'})\n",
    "        #name = name.find('div', {\"class\":\"moneyprice_bx\"})\n",
    "        #name = name.find(\"h1\", {\"class\":\"pcstname\"}).text\n",
    "        #print(name)\n",
    "\n",
    "        #----------------Heading\n",
    "        head = page.findAll(\"div\", {\"class\":\"heade14txt\"})[0].text\n",
    "        heading = head.split()[0:2]\n",
    "        heading = heading[0]+\" \"+heading[1]\n",
    "        heading = heading.title()\n",
    "\n",
    "        #----------------Table\n",
    "        tabl = page.find(\"div\", {\"class\":\"mt15 CTR pb20\"})\n",
    "        tabl = tabl.find(\"div\", {\"class\":\"mt15\"})\n",
    "        tabl = tabl.find(\"table\", {\"class\":\"mctable1\"}).findAll(\"tr\")\n",
    "\n",
    "        row = {}\n",
    "        for i in range(0, len(tabl)):\n",
    "            row.update({tabl[i].findAll(\"td\")[0].text:tabl[i].findAll(\"td\")[1].text})\n",
    "\n",
    "        #----------------DataFrame\n",
    "        data = pd.DataFrame(row.items(), columns=(heading,\"Values\"))\n",
    "        data = data.set_index(data.columns[0])\n",
    "        #print(data,\"\\n\\n\")\n",
    "        \n",
    "#         #----------------Inserting into DataBase\n",
    "#         insert_to_outputDB(name, heading, data['Values'][0], data['Values'][1], data['Values'][2])\n",
    "#         show_data(\"output_database\")\n",
    "        \n",
    "\n",
    "        #----------------Save to CSV\n",
    "        #data.to_csv('index.csv')\n",
    "        return data, heading\n",
    "        \n",
    "    #----------------Function Calling\n",
    "    url = urls\n",
    "    html_name = file_saving(url)\n",
    "    csvdata, heading = scrapping(html_name)\n",
    "    \n",
    "    #----------------HTML File Delete\n",
    "    os.remove(html_name)\n",
    "    \n",
    "    #----------------CSV File Returning\n",
    "    return csvdata, heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "\n",
    "def insert_to_inputDB(CName, Lin, Stats):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    sql = \"INSERT INTO input_database (CompanyName, Link, Status) VALUES (%s, %s, %s)\"\n",
    "    val = (CName, Lin, Stats)\n",
    "    \n",
    "    mycursor.execute(sql, val)\n",
    "    mydb.commit()\n",
    "    mydb.close()\n",
    "\n",
    "def insert_to_outputDB(Input_Company_Id, Rate, Averages, Indicators, Crossovers, Date):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    sql = \"INSERT INTO output_database (CompanyId, Ratings, MovingAverages, TechnicalIndicators, MovingAveragesCrossovers, Date) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    val = (Input_Company_Id, Rate, Averages, Indicators, Crossovers, Date)\n",
    "    \n",
    "    mycursor.execute(sql, val)\n",
    "    mydb.commit()\n",
    "    mydb.close()\n",
    "    \n",
    "def save_table_to_csv(table_name):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    mycursor.execute(\"SHOW columns FROM {}\".format(table_name))\n",
    "    columns_name = mycursor.fetchall()\n",
    "\n",
    "    mycursor.execute(\"SELECT * FROM {}\".format(table_name))\n",
    "    rows = mycursor.fetchall()\n",
    "    mydb.close()\n",
    "\n",
    "    colums = []\n",
    "    for i in range(0, len(columns_name)):\n",
    "        colums.append(columns_name[i][0])\n",
    "\n",
    "    d = pd.DataFrame(rows, columns=colums)\n",
    "    d = d.set_index(d.columns[0])\n",
    "    d.to_csv('{}.csv'.format(table_name))\n",
    "    print(\"Done\")\n",
    "\n",
    "def show_data(table_name):\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    mycursor.execute(\"SELECT * FROM {}\".format(table_name))\n",
    "    for i in mycursor:\n",
    "        print(i)\n",
    "    mydb.close()\n",
    "    \n",
    "def delete_row(table_name, Id):\n",
    "    if table_name == \"output_database\":\n",
    "        mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "        mycursor = mydb.cursor()    \n",
    "        mycursor.execute(\"DELETE FROM {} WHERE Id={}\".format(table_name, Id))\n",
    "        mydb.commit()\n",
    "        mydb.close()\n",
    "        \n",
    "    elif table_name == \"input_database\":\n",
    "        mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "        mycursor = mydb.cursor()    \n",
    "        mycursor.execute(\"DELETE FROM {} WHERE CompanyId={}\".format(table_name, Id))\n",
    "        mydb.commit()\n",
    "        mydb.close()\n",
    "        \n",
    "    else:\n",
    "        print(\"Give Correct Table Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import datetime\n",
    "\n",
    "def scrap_and_DB():\n",
    "    mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "    mycursor = mydb.cursor()\n",
    "    mycursor.execute(\"SELECT * FROM input_database\")\n",
    "    rows = mycursor.fetchall()\n",
    "    mydb.close()\n",
    "    for i in range(0, len(rows)):\n",
    "        if rows[i][3] == 1:\n",
    "            time1 = datetime.datetime.now()\n",
    "            \n",
    "            csv_data, rating = web_scrapping(rows[i][2])\n",
    "            \n",
    "            time2 = datetime.datetime.now()\n",
    "#             print(\"\\n\\nTotal Time Taken To Scrap {} is -------------------------> \", time2-time1,\"\\n\".format(rows[i][1]))\n",
    "            \n",
    "            insert_to_outputDB(rows[i][0], rating, csv_data['Values'][0], csv_data['Values'][1], csv_data['Values'][2], time2)\n",
    "        else:\n",
    "            print(\"Status of {} having Company_Id = {} is 0. Please check\\n\".format(rows[i][1], rows[i][0]))\n",
    "    \n",
    "    print(\"\\nScrap & DB Done Take a Look\\n\")\n",
    "    show_data(\"output_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Total Time Taken To Scrap {} is ------------------------->  0:00:21.749390 \n",
      "\n",
      "\n",
      "\n",
      "Total Time Taken To Scrap {} is ------------------------->  0:00:22.557266 \n",
      "\n",
      "\n",
      "\n",
      "Total Time Taken To Scrap {} is ------------------------->  0:00:23.744108 \n",
      "\n",
      "Status of Vodafone Idea Ltd. having Company_Id = 4 is 0. Please check\n",
      "\n",
      "\n",
      "Total Time Taken To Scrap {} is ------------------------->  0:00:22.396489 \n",
      "\n",
      "Scrap & DB Done Take a Look\n",
      "\n",
      "(1, 1, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 16, 28, 4))\n",
      "(2, 2, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 16, 28, 26))\n",
      "(3, 3, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 16, 28, 50))\n",
      "(4, 5, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 16, 29, 13))\n"
     ]
    }
   ],
   "source": [
    "scrap_and_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete Row\n",
    "for i in range(0,9):\n",
    "    delete_row(\"output_database\", i)\n",
    "show_data(\"output_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'ICICI Bank Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/icicibank/ICI02', 1)\n",
      "(2, 'Reliance Industries Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/refineries/relianceindustries/RI', 1)\n",
      "(3, 'State Bank of India', 'https://www.moneycontrol.com/india/stockpricequote/banks-public-sector/statebankindia/SBI', 1)\n",
      "(4, 'Vodafone Idea Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/telecommunications-service/vodafoneidealimited/IC8', 0)\n",
      "(5, 'Infosys Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT', 1)\n"
     ]
    }
   ],
   "source": [
    "#Insert In Input\n",
    "insert_to_inputDB(\"Infosys Ltd.\", 'https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT', 1)\n",
    "show_data(\"input_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'ICICI Bank Ltd.', 'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/icicibank/ICI02', 1)\n"
     ]
    }
   ],
   "source": [
    "#Update Query\n",
    "\n",
    "mydb = mysql.connect(host=\"localhost\", user=\"root\", password=\"manthanmysql\", database=\"moneycontrol\")\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"UPDATE input_database SET Status = 1 WHERE CompanyId = 1\")\n",
    "mydb.commit()\n",
    "mydb.close()\n",
    "show_data(\"input_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Vodafone Idea Ltd. having Company_Id = 4 is 0. Please check\n",
      "\n",
      "Scrap & DB Done Take a Look\n",
      "\n",
      "(1, 1, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 20, 48, 1))\n",
      "(2, 2, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 20, 48, 51))\n",
      "(3, 3, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 20, 49, 12))\n",
      "(4, 5, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 20, 49, 33))\n",
      "Status of Vodafone Idea Ltd. having Company_Id = 4 is 0. Please check\n",
      "\n",
      "Scrap & DB Done Take a Look\n",
      "\n",
      "(1, 1, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 20, 48, 1))\n",
      "(2, 2, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 20, 48, 51))\n",
      "(3, 3, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 20, 49, 12))\n",
      "(4, 5, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 20, 49, 33))\n",
      "(5, 1, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 20, 54, 54))\n",
      "(6, 2, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 20, 55, 16))\n",
      "(7, 3, 'Technical Rating', 'Bullish', 'Bullish', 'Bullish', datetime.datetime(2020, 8, 31, 20, 55, 36))\n",
      "(8, 5, 'Technical Rating', 'Neutral', 'Neutral', 'Neutral', datetime.datetime(2020, 8, 31, 20, 55, 57))\n"
     ]
    }
   ],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "# def job():\n",
    "#     scrap_and_DB()\n",
    "#     print(datetime.datetime.now())\n",
    "\n",
    "schedule.every(5).minutes.do(scrap_and_DB)\n",
    "# schedule.every().hour.do(job)\n",
    "# schedule.every().day.at(\"10:30\").do(job)\n",
    "# schedule.every(5).to(10).minutes.do(job)\n",
    "# schedule.every().monday.do(job)\n",
    "# schedule.every().wednesday.at(\"13:15\").do(job)\n",
    "# schedule.every().minute.at(\":17\").do(job)\n",
    "# schedule.every(10).seconds.do(job)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = page.findAll(\"div\", {\"class\":\"heade14txt\"})[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technical Rating'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading = head.split()[0:2]\n",
    "heading = heading[0]+\" \"+heading[1]\n",
    "heading = heading.title()\n",
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabl = page.find(\"div\", {\"class\":\"mt15 CTR pb20\"})\n",
    "tabl = tabl.find(\"div\", {\"class\":\"mt15\"})\n",
    "tabl = tabl.find(\"table\", {\"class\":\"mctable1\"}).findAll(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {}\n",
    "for i in range(0, len(tabl)):\n",
    "    row.update({tabl[i].findAll(\"td\")[0].text:tabl[i].findAll(\"td\")[1].text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = []\n",
    "# row_1 = []\n",
    "# row_2 = []\n",
    "# for i in range(0, len(tabl)):\n",
    "#     row_1.append(tabl[i].findAll(\"td\")[0].text)\n",
    "#     row_2.append(tabl[i].findAll(\"td\")[1].text)\n",
    "# row.append(row_1)\n",
    "# row.append(row_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Moving Averages': 'Bullish',\n",
       " ' Technical Indicators': 'Bullish',\n",
       " 'Moving Averages Crossovers': 'Bullish'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(row.items(), columns=(heading,None))\n",
    "data = data.set_index(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('infosys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "\n",
    "# def get_html(url):\n",
    "#     f=open('htmlcode.txt','w')\n",
    "#     page=urllib.request.urlopen(url)\n",
    "#     pagetext=page.read() ## Save the html and later save in the file\n",
    "#     f.write(pagetext)\n",
    "#     f.close()\n",
    "    \n",
    "# get_html(\"https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT.html\")\n",
    "\n",
    "# import urllib.request\n",
    "\n",
    "# urllib.request.urlretrieve(\"https://www.moneycontrol.com/india/stockpricequote/computers-software/infosys/IT.html\", \"test.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
